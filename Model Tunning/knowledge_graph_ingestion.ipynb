{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "626d8f44",
   "metadata": {},
   "source": [
    "### Set up and environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d12b98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\python\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain_experimental in c:\\python\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: langchain_community in c:\\python\\lib\\site-packages (0.3.30)\n",
      "Requirement already satisfied: langchain-google-genai in c:\\python\\lib\\site-packages (2.1.12)\n",
      "Requirement already satisfied: neo4j in c:\\python\\lib\\site-packages (5.28.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\python\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\python\\lib\\site-packages (4.13.5)\n",
      "Requirement already satisfied: pandas in c:\\python\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: tabulate in c:\\python\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\python\\lib\\site-packages (from langchain) (0.3.78)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\python\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\python\\lib\\site-packages (from langchain) (0.4.32)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\python\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\python\\lib\\site-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\python\\lib\\site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\python\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\python\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\python\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\python\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.12.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\python\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\python\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\python\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\python\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\python\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\python\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\python\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\python\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\python\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\python\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\python\\lib\\site-packages (from langchain_community) (3.12.15)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\python\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\python\\lib\\site-packages (from langchain_community) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\python\\lib\\site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\python\\lib\\site-packages (from langchain_community) (2.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\python\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\python\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\python\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<1,>=0.7 in c:\\python\\lib\\site-packages (from langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: filetype<2,>=1.2 in c:\\python\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\python\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.25.2)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\python\\lib\\site-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.41.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\python\\lib\\site-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\python\\lib\\site-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (6.32.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\python\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\python\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.75.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\python\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.75.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\python\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (6.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\python\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: pytz in c:\\python\\lib\\site-packages (from neo4j) (2025.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python\\lib\\site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Project Root Directory identified as: c:\\Users\\Akshit Aggarwal\\Space-Biology-Knowledge-Engine\n",
      "Attempting to load .env file from: c:\\Users\\Akshit Aggarwal\\Space-Biology-Knowledge-Engine\\Backend\\.env\n",
      "Successfully loaded environment variables.\n",
      "Setup complete. All paths are now absolute and robust.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install langchain langchain_experimental langchain_community langchain-google-genai neo4j python-dotenv beautifulsoup4 pandas tabulate\n",
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# Define the project's absolute root directory\n",
    "# Assumes your notebook is in a subfolder like 'Model Tunning'\n",
    "ROOT_DIR = Path.cwd().parent\n",
    "print(f\"Project Root Directory identified as: {ROOT_DIR}\")\n",
    "\n",
    "# Construct absolute paths from the root directory\n",
    "dotenv_path = ROOT_DIR / \"Backend\" / \".env\"\n",
    "DATA_DIR = ROOT_DIR / \"Research Data set\"\n",
    "\n",
    "# Load environment variables from the correct, absolute path\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "print(f\"Attempting to load .env file from: {dotenv_path}\")\n",
    "\n",
    "# Neo4j Credentials\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# Google API Key\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Verification Step\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found. Check the path to your .env file and the variable name.\")\n",
    "if not NEO4J_URI:\n",
    "    raise ValueError(\"NEO4J credentials not found. Check the path to your .env file.\")\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "print(\"Successfully loaded environment variables.\")\n",
    "\n",
    "# --- File Paths (now constructed from the absolute DATA_DIR) ---\n",
    "TEXT_FOLDER = DATA_DIR / \"text\"\n",
    "TABLES_FOLDER = DATA_DIR / \"tables_data\"\n",
    "IMAGES_FILE = DATA_DIR / \"images_data.json\"\n",
    "CSV_FILE = DATA_DIR / \"SB_publication_PMC.csv\"\n",
    "\n",
    "print(\"Setup complete. All paths are now absolute and robust.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631ca81f",
   "metadata": {},
   "source": [
    "### Initializing connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af67172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshit Aggarwal\\AppData\\Local\\Temp\\ipykernel_14080\\4024968618.py:4: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
      "  graph = Neo4jGraph(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph schema defined and connections initialized.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# --- Initialize Connections ---\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")\n",
    "\n",
    "# Initialize models with an explicit timeout for resilience\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0, request_timeout=120)\n",
    "llm_vision = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0, request_timeout=120)\n",
    "\n",
    "# --- Define Graph Schema ---\n",
    "system_prompt = \"\"\"\n",
    "You are a brilliant NASA biologist and data scientist. Your task is to extract a knowledge graph from the provided research paper text.\n",
    "\n",
    "1.  **Nodes**: Identify all relevant entities. For each entity, provide a unique 'id' (its name) and a 'type' from the following categories:\n",
    "    * `Paper`, `BioEntity`, `Concept`, `Stressor`, `Organism`, `MissionContext`, `Application`, `Institution`.\n",
    "\n",
    "2.  **Relationships**: Identify the relationships between these entities. Use the following relationship types:\n",
    "    * `AFFECTS`: Primary relationship for findings. Add an 'effect' property (e.g., 'upregulates', 'inhibits') and an 'evidence' property with the supporting text snippet.\n",
    "    * `INVESTIGATES`, `STUDIED_IN`, `PART_OF`, `HAS_POTENTIAL`, `AFFILIATED_WITH`.\n",
    "\n",
    "Provide the output as a list of graph nodes and a list of graph relationships. Do not add any nodes or relationships that are not explicitly mentioned in the text.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "print(\"Graph schema defined and connections initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f62122",
   "metadata": {},
   "source": [
    "### Unified context processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "581d02a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing functions optimized for performance and correct syntax.\n"
     ]
    }
   ],
   "source": [
    "def process_and_enrich_graph(graph_documents, base_node):\n",
    "    \"\"\"Adds graph documents and links them to a base node in a single batch.\"\"\"\n",
    "    if not graph_documents:\n",
    "        return\n",
    "\n",
    "    # Add the extracted nodes and relationships to the graph\n",
    "    graph.add_graph_documents(graph_documents)\n",
    "\n",
    "    # Batch-link all new non-Paper nodes to the base Paper node\n",
    "    paper_id = base_node['properties']['id']\n",
    "    node_ids_to_link = []\n",
    "    for doc in graph_documents:\n",
    "        for node in doc.nodes:\n",
    "            if node.type != 'Paper':\n",
    "                node_ids_to_link.append(node.id)\n",
    "\n",
    "    if node_ids_to_link:\n",
    "        graph.query(\"\"\"\n",
    "        MATCH (p:Paper {id: $paper_id})\n",
    "        UNWIND $node_ids AS node_id\n",
    "        MATCH (n) WHERE n.id = node_id\n",
    "        MERGE (p)-[:MENTIONS]->(n)\n",
    "        \"\"\", params={\"paper_id\": paper_id, \"node_ids\": node_ids_to_link})\n",
    "\n",
    "def process_text_chunk(text_chunk, paper_node):\n",
    "    if not text_chunk.strip():\n",
    "        return\n",
    "    print(f\"  Processing text chunk of {len(text_chunk)} chars...\")\n",
    "    document = Document(page_content=text_chunk)\n",
    "    graph_documents = transformer.convert_to_graph_documents([document])\n",
    "    process_and_enrich_graph(graph_documents, paper_node)\n",
    "\n",
    "def process_table(pmc_id, table_id_local, context_text, paper_node):\n",
    "    table_filename = f\"{pmc_id}_{table_id_local}.csv\"\n",
    "    print(f\"  Processing table: {table_filename}...\")\n",
    "    table_csv_path = os.path.join(TABLES_FOLDER, table_filename)\n",
    "    if not os.path.exists(table_csv_path): return\n",
    "\n",
    "    try:\n",
    "        table_string = pd.read_csv(table_csv_path).to_markdown(index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"    [ERROR] Could not parse CSV {table_filename}: {e}\"); return\n",
    "\n",
    "    document = Document(page_content=f\"CONTEXT: \\\"{context_text}\\\"\\n---\\nTABLE DATA:\\n{table_string}\")\n",
    "    graph_documents = transformer.convert_to_graph_documents([document])\n",
    "    process_and_enrich_graph(graph_documents, paper_node)\n",
    "\n",
    "    # Link Visual Evidence in a single, efficient query\n",
    "    unique_table_id = f\"{pmc_id}_{table_id_local}\"\n",
    "    concept_ids = [node.id for doc in graph_documents for node in doc.nodes if node.type != 'Paper']\n",
    "    if concept_ids:\n",
    "        graph.query(\"\"\"\n",
    "        MATCH (p:Paper {id: $pmc_id})\n",
    "        MERGE (v:VisualEvidence {id: $unique_id, type: 'Table', content: $filename, caption: $caption})\n",
    "        MERGE (p)-[:HAS_EVIDENCE]->(v)\n",
    "        WITH v, $concept_ids AS concept_ids\n",
    "        UNWIND concept_ids AS concept_id\n",
    "        MATCH (c) WHERE c.id = concept_id\n",
    "        MERGE (v)-[:ILLUSTRATES]->(c)\n",
    "        \"\"\", params={\n",
    "            \"pmc_id\": pmc_id, \"unique_id\": unique_table_id,\n",
    "            \"filename\": table_filename, \"caption\": context_text,\n",
    "            \"concept_ids\": concept_ids\n",
    "        })\n",
    "\n",
    "def process_image(pmc_id, image_id_local, context_text, paper_node, image_url_map):\n",
    "    print(f\"  Processing image: {image_id_local} for paper {pmc_id}...\")\n",
    "    try:\n",
    "        image_url = image_url_map[pmc_id][image_id_local]\n",
    "    except KeyError:\n",
    "        print(f\"    [WARN] Image URL not found for {pmc_id} -> {image_id_local}\"); return\n",
    "\n",
    "    message = HumanMessage(content=[\n",
    "        {\"type\": \"text\", \"text\": f\"CAPTION CONTEXT: \\\"{context_text}\\\"\\n---\\nDescribe the primary scientific finding from the image.\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": image_url},\n",
    "    ])\n",
    "    response = llm_vision.invoke([message])\n",
    "    finding_text = response.content\n",
    "\n",
    "    if finding_text:\n",
    "        document = Document(page_content=finding_text)\n",
    "        graph_documents = transformer.convert_to_graph_documents([document])\n",
    "        process_and_enrich_graph(graph_documents, paper_node)\n",
    "\n",
    "        unique_image_id = f\"{pmc_id}_{image_id_local}\"\n",
    "        concept_ids = [node.id for doc in graph_documents for node in doc.nodes if node.type != 'Paper']\n",
    "        if concept_ids:\n",
    "            graph.query(\"\"\"\n",
    "            MATCH (p:Paper {id: $pmc_id})\n",
    "            MERGE (v:VisualEvidence {id: $unique_id, type: 'Image', content: $url, caption: $caption})\n",
    "            MERGE (p)-[:HAS_EVIDENCE]->(v)\n",
    "            WITH v, $concept_ids AS concept_ids\n",
    "            UNWIND concept_ids AS concept_id\n",
    "            MATCH (c) WHERE c.id = concept_id\n",
    "            MERGE (v)-[:ILLUSTRATES]->(c)\n",
    "            \"\"\", params={\n",
    "                \"pmc_id\": pmc_id, \"unique_id\": unique_image_id,\n",
    "                \"url\": image_url, \"caption\": context_text,\n",
    "                \"concept_ids\": concept_ids\n",
    "            })\n",
    "\n",
    "print(\"Processing functions optimized for performance and correct syntax.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72e6ca4",
   "metadata": {},
   "source": [
    "### Main Ingestion Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee28a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supporting data loaded and pre-processed.\n",
      "\n",
      "--- Processing Paper: PMC10020673 ---\n",
      "  Ensuring a clean slate for PMC10020673...\n",
      "  Processing text chunk of 8 chars...\n",
      "  Processing text chunk of 1494 chars...\n",
      "  Processing text chunk of 1031 chars...\n",
      "  Processing text chunk of 760 chars...\n",
      "  Processing text chunk of 1498 chars...\n",
      "  Processing text chunk of 289 chars...\n",
      "  Processing text chunk of 9 chars...\n",
      "  Processing image: Img001 for paper PMC10020673...\n",
      "  Processing text chunk of 151 chars...\n",
      "  Processing text chunk of 1436 chars...\n",
      "  Processing text chunk of 750 chars...\n",
      "  Processing text chunk of 1460 chars...\n",
      "  Processing text chunk of 1363 chars...\n",
      "  Processing text chunk of 1494 chars...\n",
      "  Processing text chunk of 207 chars...\n",
      "  Processing text chunk of 842 chars...\n",
      "  Processing text chunk of 1493 chars...\n",
      "  Processing text chunk of 456 chars...\n",
      "  Processing text chunk of 947 chars...\n",
      "  Processing text chunk of 732 chars...\n",
      "  Processing text chunk of 1240 chars...\n",
      "  Processing text chunk of 1195 chars...\n",
      "  Processing text chunk of 1071 chars...\n",
      "  Processing text chunk of 1424 chars...\n",
      "  Processing text chunk of 1053 chars...\n",
      "  Processing text chunk of 1477 chars...\n",
      "  Processing text chunk of 1468 chars...\n",
      "  Processing text chunk of 34 chars...\n",
      "  Processing text chunk of 1484 chars...\n",
      "  Processing text chunk of 429 chars...\n",
      "  Processing text chunk of 1490 chars...\n",
      "  Processing table: PMC10020673_table001.csv...\n",
      "  Processing text chunk of 1489 chars...\n",
      "  Processing text chunk of 249 chars...\n",
      "  Processing table: PMC10020673_table002.csv...\n",
      "  Processing text chunk of 516 chars...\n",
      "  Processing image: Img002 for paper PMC10020673...\n",
      "  Processing text chunk of 1460 chars...\n",
      "  Processing text chunk of 174 chars...\n",
      "  Processing table: PMC10020673_table003.csv...\n",
      "  Processing text chunk of 585 chars...\n",
      "  Processing text chunk of 1462 chars...\n",
      "  Processing image: Img003 for paper PMC10020673...\n",
      "  Processing text chunk of 1076 chars...\n",
      "  Processing text chunk of 1485 chars...\n",
      "  Processing text chunk of 581 chars...\n",
      "  Processing text chunk of 1452 chars...\n",
      "  Processing text chunk of 886 chars...\n",
      "  Processing image: Img004 for paper PMC10020673...\n",
      "  Processing text chunk of 1013 chars...\n",
      "  Processing text chunk of 888 chars...\n",
      "  Processing text chunk of 1050 chars...\n",
      "  Processing image: Img005 for paper PMC10020673...\n",
      "  Processing text chunk of 513 chars...\n",
      "  Processing text chunk of 1311 chars...\n",
      "  Processing image: Img006 for paper PMC10020673...\n",
      "  Processing text chunk of 652 chars...\n",
      "  Processing text chunk of 1495 chars...\n",
      "  Processing text chunk of 903 chars...\n",
      "  Processing image: Img007 for paper PMC10020673...\n",
      "  Processing text chunk of 862 chars...\n",
      "  Processing text chunk of 1242 chars...\n",
      "  Processing text chunk of 767 chars...\n",
      "  Processing text chunk of 1497 chars...\n",
      "  Processing text chunk of 1086 chars...\n",
      "  Processing text chunk of 170 chars...\n",
      "  Processing text chunk of 1495 chars...\n",
      "  Processing text chunk of 722 chars...\n",
      "  Processing text chunk of 1312 chars...\n",
      "\n",
      "--- Processing Paper: PMC10025027 ---\n",
      "  Ensuring a clean slate for PMC10025027...\n",
      "  Processing text chunk of 8 chars...\n",
      "  Processing text chunk of 1498 chars...\n",
      "  Processing text chunk of 590 chars...\n",
      "  Processing text chunk of 1276 chars...\n",
      "  Processing text chunk of 1349 chars...\n",
      "  Processing text chunk of 1486 chars...\n",
      "  Processing text chunk of 1161 chars...\n",
      "  Processing text chunk of 1484 chars...\n",
      "  Processing text chunk of 1422 chars...\n",
      "  Processing image: Img001 for paper PMC10025027...\n",
      "  Processing text chunk of 784 chars...\n",
      "  Processing table: PMC10025027_table001.csv...\n"
     ]
    }
   ],
   "source": [
    "# --- Main Processing Loop ---\n",
    "try:\n",
    "    with open(IMAGES_FILE, 'r') as f:\n",
    "        image_url_map = json.load(f)\n",
    "    papers_df = pd.read_csv(CSV_FILE)\n",
    "    papers_df['pmc_id'] = papers_df['Link'].str.extract(r'(PMC\\d+)', expand=False)\n",
    "    papers_df.dropna(subset=['pmc_id'], inplace=True)\n",
    "    id_to_title_map = pd.Series(papers_df.Title.values, index=papers_df.pmc_id).to_dict()\n",
    "    id_to_url_map = pd.Series(papers_df.Link.values, index=papers_df.pmc_id).to_dict()\n",
    "    print(\"Supporting data loaded and pre-processed.\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Could not load or process supporting data files: {e}\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "text_files = [f for f in os.listdir(TEXT_FOLDER) if f.endswith('.txt')]\n",
    "media_pattern = re.compile(r'(table\\d+|Img\\d+)')\n",
    "\n",
    "# Processing a subset of 20 papers for your sprint run.\n",
    "for filename in text_files[:20]:\n",
    "    pmc_id = os.path.splitext(filename)[0]\n",
    "    print(f\"\\n--- Processing Paper: {pmc_id} ---\")\n",
    "\n",
    "    # --- CRITICAL FIX: Safe, Transactional Cleanup ---\n",
    "    # This query safely removes only the specific contributions of this paper,\n",
    "    # leaving shared knowledge nodes intact.\n",
    "    try:\n",
    "        print(f\"  Ensuring a clean slate for {pmc_id}...\")\n",
    "        graph.query(\"\"\"\n",
    "        MATCH (p:Paper {id: $pmc_id})\n",
    "        OPTIONAL MATCH (p)-[:HAS_EVIDENCE]->(v:VisualEvidence)\n",
    "        DETACH DELETE v\n",
    "        \"\"\", params={\"pmc_id\": pmc_id})\n",
    "        graph.query(\"\"\"\n",
    "        MATCH (p:Paper {id: $pmc_id})-[r:MENTIONS]->(n)\n",
    "        DELETE r\n",
    "        \"\"\", params={\"pmc_id\": pmc_id})\n",
    "    except Exception as e:\n",
    "        print(f\"  [WARN] Could not perform cleanup for {pmc_id}. Error: {e}\")\n",
    "\n",
    "    paper_title = id_to_title_map.get(pmc_id, \"Title Not Found\")\n",
    "    paper_url = id_to_url_map.get(pmc_id, \"URL Not Found\")\n",
    "\n",
    "    if \"Not Found\" in paper_title:\n",
    "        print(f\"  [WARN] Metadata for {pmc_id} not found in CSV. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    graph.query(\n",
    "        \"MERGE (p:Paper {id: $id}) SET p.title = $title, p.url = $url\",\n",
    "        params={\"id\": pmc_id, \"title\": paper_title, \"url\": paper_url}\n",
    "    )\n",
    "    paper_node = {\"type\": \"Paper\", \"properties\": {\"id\": pmc_id}}\n",
    "\n",
    "    file_path = os.path.join(TEXT_FOLDER, filename)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        full_text = f.read()\n",
    "\n",
    "    last_end = 0\n",
    "    for match in media_pattern.finditer(full_text):\n",
    "        start, end = match.span()\n",
    "        media_id_local = match.group(0)\n",
    "\n",
    "        large_text_chunk = full_text[last_end:start]\n",
    "        small_text_chunks = text_splitter.split_text(large_text_chunk)\n",
    "        for chunk in small_text_chunks:\n",
    "            process_text_chunk(chunk, paper_node)\n",
    "\n",
    "        context_start = max(0, start - 250)\n",
    "        context_end = min(len(full_text), end + 250)\n",
    "        context_text = full_text[context_start:context_end]\n",
    "\n",
    "        if media_id_local.startswith('table'):\n",
    "            process_table(pmc_id, media_id_local, context_text, paper_node)\n",
    "        elif media_id_local.startswith('Img'):\n",
    "            process_image(pmc_id, media_id_local, context_text, paper_node, image_url_map)\n",
    "        \n",
    "        last_end = end\n",
    "\n",
    "    remaining_text = full_text[last_end:]\n",
    "    small_text_chunks = text_splitter.split_text(remaining_text)\n",
    "    for chunk in small_text_chunks:\n",
    "        process_text_chunk(chunk, paper_node)\n",
    "\n",
    "print(\"\\n--- Sprint Ingestion Complete! ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
