{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "626d8f44",
   "metadata": {},
   "source": [
    "### Set up and environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8607e911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain_experimental in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.30)\n",
      "Requirement already satisfied: langchain-google-genai in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.1.12)\n",
      "Requirement already satisfied: neo4j in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.28.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.14.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (0.3.77)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (0.4.31)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (2.11.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.13.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (3.12.15)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (2.2.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<1,>=0.7 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: filetype<2,>=1.2 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.41.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (6.32.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.75.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.75.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from neo4j) (2025.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\surya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Project Root Directory identified as: d:\\Astro-NOTS\\Space-Biology-Knowledge-Engine\n",
      "Attempting to load .env file from: d:\\Astro-NOTS\\Space-Biology-Knowledge-Engine\\Backend\\.env\n",
      "Successfully loaded environment variables.\n",
      "Setup complete. All paths are now absolute and robust.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install langchain langchain_experimental langchain_community langchain-google-genai neo4j python-dotenv beautifulsoup4 pandas\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# --- FIX: Define the project's absolute root directory ---\n",
    "# This assumes your notebook is in a subfolder like 'Model Tunning'\n",
    "# It goes up one level to find the root.\n",
    "ROOT_DIR = Path.cwd().parent\n",
    "print(f\"Project Root Directory identified as: {ROOT_DIR}\")\n",
    "\n",
    "# Construct absolute paths from the root directory\n",
    "dotenv_path = ROOT_DIR / \"Backend\" / \".env\"\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "\n",
    "# Load environment variables from the correct, absolute path\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "print(f\"Attempting to load .env file from: {dotenv_path}\")\n",
    "\n",
    "# Neo4j Credentials\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# Google API Key\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Verification Step\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found. Check the path to your .env file and the variable name.\")\n",
    "if not NEO4J_URI:\n",
    "    raise ValueError(\"NEO4J credentials not found. Check the path to your .env file.\")\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "print(\"Successfully loaded environment variables.\")\n",
    "\n",
    "# --- File Paths (now constructed from the absolute DATA_DIR) ---\n",
    "TEXT_FOLDER = DATA_DIR / \"text\"\n",
    "TABLES_FOLDER = DATA_DIR / \"tables_data\"\n",
    "IMAGES_FILE = DATA_DIR / \"images_data.json\"\n",
    "CSV_FILE = DATA_DIR / \"SB_publication_PMC.csv\"\n",
    "\n",
    "print(\"Setup complete. All paths are now absolute and robust.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631ca81f",
   "metadata": {},
   "source": [
    "### Initializing connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f62bdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_40228\\3063079326.py:2: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
      "  graph = Neo4jGraph(\n",
      "Unable to retrieve routing information\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not connect to Neo4j database. Please ensure that the url is correct",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mServiceUnavailable\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\graphs\\neo4j_graph.py:415\u001b[39m, in \u001b[36mNeo4jGraph.__init__\u001b[39m\u001b[34m(self, url, username, password, database, timeout, sanitize, refresh_schema, driver_config, enhanced_schema)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_driver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify_connectivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j.exceptions.ServiceUnavailable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\neo4j\\_sync\\driver.py:1090\u001b[39m, in \u001b[36mDriver.verify_connectivity\u001b[39m\u001b[34m(self, **config)\u001b[39m\n\u001b[32m   1089\u001b[39m session_config = \u001b[38;5;28mself\u001b[39m._read_session_config(config)\n\u001b[32m-> \u001b[39m\u001b[32m1090\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_server_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\neo4j\\_sync\\driver.py:1305\u001b[39m, in \u001b[36mDriver._get_server_info\u001b[39m\u001b[34m(self, session_config)\u001b[39m\n\u001b[32m   1304\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._session(session_config) \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m-> \u001b[39m\u001b[32m1305\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_server_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:183\u001b[39m, in \u001b[36mSession._get_server_info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mREAD_ACCESS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mliveness_check_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munprepared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    185\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m server_info = \u001b[38;5;28mself\u001b[39m._connection.server_info\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:136\u001b[39m, in \u001b[36mSession._connect\u001b[39m\u001b[34m(self, access_mode, **acquire_kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43macquire_kwargs\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.CancelledError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\neo4j\\_sync\\work\\workspace.py:186\u001b[39m, in \u001b[36mWorkspace._connect\u001b[39m\u001b[34m(self, access_mode, auth, **acquire_kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m ssr_enabled = \u001b[38;5;28mself\u001b[39m._pool.ssr_enabled\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m target_db = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_routing_target_database\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43macquire_auth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssr_enabled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssr_enabled\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m acquire_kwargs_ = {\n\u001b[32m    190\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33maccess_mode\u001b[39m\u001b[33m\"\u001b[39m: access_mode,\n\u001b[32m    191\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: acquisition_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m    196\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdatabase_callback\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._make_db_resolution_callback(),\n\u001b[32m    197\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\neo4j\\_sync\\work\\workspace.py:260\u001b[39m, in \u001b[36mWorkspace._get_routing_target_database\u001b[39m\u001b[34m(self, acquire_auth, ssr_enabled)\u001b[39m\n\u001b[32m    259\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33m[#0000]  _: <WORKSPACE> resolve home database\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_routing_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimp_user\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimpersonated_user\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbookmarks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_bookmarks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43macquire_auth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43macquisition_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43macquisition_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_db_resolution_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m AcquisitionDatabase(\u001b[38;5;28mself\u001b[39m._config.database)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:1025\u001b[39m, in \u001b[36mNeo4jPool.update_routing_table\u001b[39m\u001b[34m(self, database, imp_user, bookmarks, auth, acquisition_timeout, database_callback)\u001b[39m\n\u001b[32m   1024\u001b[39m log.error(\u001b[33m\"\u001b[39m\u001b[33mUnable to retrieve routing information\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\u001b[33m\"\u001b[39m\u001b[33mUnable to retrieve routing information\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mServiceUnavailable\u001b[39m: Unable to retrieve routing information",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- Initialize Connections ---\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m graph = \u001b[43mNeo4jGraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNEO4J_URI\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43musername\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNEO4J_USERNAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNEO4J_PASSWORD\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m llm = ChatGoogleGenerativeAI(model=\u001b[33m\"\u001b[39m\u001b[33mgemini-2.5-flash-latest\u001b[39m\u001b[33m\"\u001b[39m, temperature=\u001b[32m0\u001b[39m)\n\u001b[32m      9\u001b[39m llm_vision = ChatGoogleGenerativeAI(model=\u001b[33m\"\u001b[39m\u001b[33mgemini-2.5-flash-latest\u001b[39m\u001b[33m\"\u001b[39m, temperature=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:226\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    225\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\graphs\\neo4j_graph.py:417\u001b[39m, in \u001b[36mNeo4jGraph.__init__\u001b[39m\u001b[34m(self, url, username, password, database, timeout, sanitize, refresh_schema, driver_config, enhanced_schema)\u001b[39m\n\u001b[32m    415\u001b[39m     \u001b[38;5;28mself\u001b[39m._driver.verify_connectivity()\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j.exceptions.ServiceUnavailable:\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    418\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not connect to Neo4j database. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    419\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure that the url is correct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    420\u001b[39m     )\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j.exceptions.AuthError:\n\u001b[32m    422\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    423\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not connect to Neo4j database. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    424\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure that the username and password are correct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    425\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Could not connect to Neo4j database. Please ensure that the url is correct"
     ]
    }
   ],
   "source": [
    "# --- Initialize Connections ---\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-latest\", temperature=0)\n",
    "llm_vision = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-latest\", temperature=0)\n",
    "\n",
    "# --- Define Graph Schema ---\n",
    "graph_creation_prompt = \"\"\"\n",
    "You are a brilliant NASA biologist and data scientist. Your task is to extract a knowledge graph from the provided research paper text.\n",
    "\n",
    "1.  **Nodes**: Identify all relevant entities and classify them into one of the following categories:\n",
    "    * `Paper`: The research paper itself.\n",
    "    * `BioEntity`: Biological components like Genes, Proteins, Cell Types, Molecules.\n",
    "    * `Concept`: Abstract ideas or processes like \"Bone Loss\", \"Oxidative Stress\", Health Risks, or Diseases.\n",
    "    * `Stressor`: Environmental factors unique to space like \"Microgravity\", \"Galactic Cosmic Rays\".\n",
    "    * `Organism`: The subject of the study (e.g., \"Mus musculus\", \"Homo sapiens\").\n",
    "    * `MissionContext`: Missions, hardware, or facilities like \"ISS Expedition 41\", \"Rodent Research-1\".\n",
    "    * `Application`: Potential real-world benefits like \"Osteoporosis Treatment\", \"Cancer Therapy\".\n",
    "    * `Institution`: Organizations involved.\n",
    "\n",
    "2.  **Relationships**: Identify the relationships between these entities. Use the following relationship types:\n",
    "    * `AFFECTS`: The primary relationship for scientific findings. **Crucially, add an `effect` property** to describe the nature of the effect (e.g., 'upregulates', 'inhibits', 'causes', 'correlates_with'). Also add an `evidence` property with the text snippet that supports the finding.\n",
    "    * `INVESTIGATES`: Connects a `Paper` to what it studies.\n",
    "    * `STUDIED_IN`: Connects a finding or entity to the `Organism`.\n",
    "    * `PART_OF`: Links research to a `MissionContext`.\n",
    "    * `HAS_POTENTIAL`: Links a finding to an `Application`.\n",
    "    * `AFFILIATED_WITH`: Connects a `Paper` to an `Institution`.\n",
    "\n",
    "Provide the output as a list of graph nodes and a list of graph relationships. Do not add any nodes or relationships that are not explicitly mentioned in the text.\n",
    "\"\"\"\n",
    "\n",
    "transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    prompt=graph_creation_prompt\n",
    ")\n",
    "\n",
    "print(\"Graph schema defined and connections initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f62122",
   "metadata": {},
   "source": [
    "### Unified context processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a84bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_chunk(text_chunk, paper_node):\n",
    "    \"\"\"Processes a plain text chunk and adds it to the graph.\"\"\"\n",
    "    if not text_chunk.strip():\n",
    "        return\n",
    "    print(f\"  Processing text chunk of {len(text_chunk)} chars...\")\n",
    "    document = Document(page_content=text_chunk)\n",
    "    graph_documents = transformer.convert_to_graph_documents([document])\n",
    "    graph.add_graph_documents(graph_documents, base=paper_node)\n",
    "\n",
    "def process_table(pmc_id, table_id_local, context_text, paper_node):\n",
    "    \"\"\"Processes a CSV table with its context.\"\"\"\n",
    "    table_filename = f\"{pmc_id}_{table_id_local}.csv\"\n",
    "    print(f\"  Processing table: {table_filename}...\")\n",
    "    table_csv_path = os.path.join(TABLES_FOLDER, table_filename)\n",
    "    if not os.path.exists(table_csv_path):\n",
    "        print(f\"    [WARN] Table CSV file not found: {table_filename}\")\n",
    "        return\n",
    "\n",
    "    # Convert CSV to a string format for the LLM\n",
    "    try:\n",
    "        df = pd.read_csv(table_csv_path)\n",
    "        table_string = df.to_markdown(index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"    [ERROR] Could not parse CSV {table_filename}: {e}\")\n",
    "        return\n",
    "\n",
    "    table_prompt = f\"\"\"\n",
    "    CONTEXT: \"{context_text}\"\n",
    "    ---\n",
    "    TABLE DATA for {table_id_local} (in Markdown format):\n",
    "    {table_string}\n",
    "    ---\n",
    "    Based on BOTH the text context and the table data, extract all relevant scientific entities and their relationships.\n",
    "    \"\"\"\n",
    "    document = Document(page_content=table_prompt)\n",
    "    graph_documents = transformer.convert_to_graph_documents([document])\n",
    "    graph.add_graph_documents(graph_documents, base=paper_node)\n",
    "\n",
    "    # Create the globally unique VisualEvidence node for the table\n",
    "    unique_table_id = f\"{pmc_id}_{table_id_local}\"\n",
    "    for doc in graph_documents:\n",
    "        for node in doc.nodes:\n",
    "            if node.label != 'Paper':\n",
    "                graph.query(\"\"\"\n",
    "                MERGE (p:Paper {id: $pmc_id})\n",
    "                MERGE (v:VisualEvidence {id: $unique_id, type: 'Table', content: $filename, caption: $caption})\n",
    "                MERGE (c:%s {id: $concept_id})\n",
    "                MERGE (v)-[:ILLUSTRATES]->(c)\n",
    "                MERGE (p)-[:HAS_EVIDENCE]->(v)\n",
    "                \"\"\" % node.label, params={\n",
    "                    \"pmc_id\": pmc_id, \"unique_id\": unique_table_id,\n",
    "                    \"filename\": table_filename, \"caption\": context_text,\n",
    "                    \"concept_id\": node.id\n",
    "                })\n",
    "\n",
    "def process_image(pmc_id, image_id_local, context_text, paper_node, image_url_map):\n",
    "    \"\"\"Processes an image using the nested JSON structure.\"\"\"\n",
    "    print(f\"  Processing image: {image_id_local} for paper {pmc_id}...\")\n",
    "    try:\n",
    "        image_url = image_url_map[pmc_id][image_id_local]\n",
    "    except KeyError:\n",
    "        print(f\"    [WARN] Image URL not found for {pmc_id} -> {image_id_local}\")\n",
    "        return\n",
    "\n",
    "    vision_prompt_text = f\"\"\"\n",
    "    CAPTION CONTEXT: \"{context_text}\"\n",
    "    ---\n",
    "    Based on the image at the provided URL and its caption, describe the primary scientific finding in one clear sentence. This sentence will be used to create knowledge graph relationships, so be precise and factual.\n",
    "    \"\"\"\n",
    "    message = HumanMessage(content=[\n",
    "        {\"type\": \"text\", \"text\": vision_prompt_text},\n",
    "        {\"type\": \"image_url\", \"image_url\": image_url},\n",
    "    ])\n",
    "\n",
    "    response = llm_vision.invoke([message])\n",
    "    finding_text = response.content\n",
    "\n",
    "    if finding_text:\n",
    "        document = Document(page_content=finding_text)\n",
    "        graph_documents = transformer.convert_to_graph_documents([document])\n",
    "        graph.add_graph_documents(graph_documents, base=paper_node)\n",
    "\n",
    "        unique_image_id = f\"{pmc_id}_{image_id_local}\"\n",
    "        for doc in graph_documents:\n",
    "            for node in doc.nodes:\n",
    "                if node.label != 'Paper':\n",
    "                    graph.query(\"\"\"\n",
    "                    MERGE (p:Paper {id: $pmc_id})\n",
    "                    MERGE (v:VisualEvidence {id: $unique_id, type: 'Image', content: $url, caption: $caption})\n",
    "                    MERGE (c:%s {id: $concept_id})\n",
    "                    MERGE (v)-[:ILLUSTRATES]->(c)\n",
    "                    MERGE (p)-[:HAS_EVIDENCE]->(v)\n",
    "                    \"\"\" % node.label, params={\n",
    "                        \"pmc_id\": pmc_id, \"unique_id\": unique_image_id,\n",
    "                        \"url\": image_url, \"caption\": context_text,\n",
    "                        \"concept_id\": node.id\n",
    "                    })\n",
    "\n",
    "print(\"Processing functions updated for new data structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72e6ca4",
   "metadata": {},
   "source": [
    "### Main Ingestion Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Processing Loop ---\n",
    "\n",
    "# 1. Load and Pre-process Supporting Data\n",
    "try:\n",
    "    with open(IMAGES_FILE, 'r') as f:\n",
    "        image_url_map = json.load(f)\n",
    "    papers_df = pd.read_csv(CSV_FILE)\n",
    "    papers_df['pmc_id'] = papers_df['Link'].str.extract(r'(PMC\\d+)', expand=False)\n",
    "    papers_df.dropna(subset=['pmc_id'], inplace=True)\n",
    "    id_to_title_map = pd.Series(papers_df.Title.values, index=papers_df.pmc_id).to_dict()\n",
    "    id_to_url_map = pd.Series(papers_df.Link.values, index=papers_df.pmc_id).to_dict()\n",
    "    print(\"Supporting data loaded and pre-processed.\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Could not load or process supporting data files: {e}\")\n",
    "\n",
    "# 2. Get list of text files to process\n",
    "text_files = [f for f in os.listdir(TEXT_FOLDER) if f.endswith('.txt')]\n",
    "\n",
    "# Regex to find all placeholders. Now matches 'table001' and 'Img001' formats.\n",
    "media_pattern = re.compile(r'(table\\d+|Img\\d+)')\n",
    "\n",
    "# 3. Iterate through each paper file\n",
    "for filename in text_files:\n",
    "    pmc_id = os.path.splitext(filename)[0]\n",
    "    print(f\"\\n--- Processing Paper: {pmc_id} ---\")\n",
    "\n",
    "    paper_title = id_to_title_map.get(pmc_id, \"Title Not Found\")\n",
    "    paper_url = id_to_url_map.get(pmc_id, \"URL Not Found\")\n",
    "\n",
    "    if \"Not Found\" in paper_title:\n",
    "        print(f\"  [WARN] Metadata for {pmc_id} not found in CSV. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    graph.query(\n",
    "        \"MERGE (p:Paper {id: $id}) SET p.title = $title, p.url = $url\",\n",
    "        params={\"id\": pmc_id, \"title\": paper_title, \"url\": paper_url}\n",
    "    )\n",
    "    paper_node = {\"type\": \"Paper\", \"properties\": {\"id\": pmc_id}}\n",
    "\n",
    "    file_path = os.path.join(TEXT_FOLDER, filename)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        full_text = f.read()\n",
    "\n",
    "    last_end = 0\n",
    "    for match in media_pattern.finditer(full_text):\n",
    "        start, end = match.span()\n",
    "        media_id_local = match.group(0)\n",
    "\n",
    "        text_chunk = full_text[last_end:start]\n",
    "        process_text_chunk(text_chunk, paper_node)\n",
    "\n",
    "        context_start = max(0, start - 250) # Increased context window\n",
    "        context_end = min(len(full_text), end + 250)\n",
    "        context_text = full_text[context_start:context_end]\n",
    "\n",
    "        if media_id_local.startswith('table'):\n",
    "            process_table(pmc_id, media_id_local, context_text, paper_node)\n",
    "        elif media_id_local.startswith('Img'):\n",
    "            process_image(pmc_id, media_id_local, context_text, paper_node, image_url_map)\n",
    "        \n",
    "        last_end = end\n",
    "\n",
    "    remaining_text = full_text[last_end:]\n",
    "    process_text_chunk(remaining_text, paper_node)\n",
    "\n",
    "print(\"\\n--- Ingestion Complete! ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
